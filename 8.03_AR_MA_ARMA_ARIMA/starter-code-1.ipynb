{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Modeling\n",
    "\n",
    "> Authors: Joseph Nelson, Justin Pounders, Matt Brems\n",
    "\n",
    "### Learning Objectives\n",
    "By the end of this lesson, students should be able to:\n",
    "- Generate and interpret ACF and PACF plots.\n",
    "- Create a proper train/test split on time series data.\n",
    "- Define stationarity.\n",
    "- Conduct and interpret an augmented Dickey-Fuller test for stationarity.\n",
    "- Construct integrated autoregressive moving average (ARIMA) models.\n",
    "- Describe when autoregressive models and moving average models are appropriate.\n",
    "- Identify the optimal values of parameters $p$, $d$, and $q$ through GridSearch.\n",
    "- Identify when seasonality exists in time series data.\n",
    "- Fit and tune a SARIMAX model.\n",
    "- Fit a multivariate time series model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this to ensure that statsmodels is version 0.9.0 and scipy is version 1.2.0.\n",
    "# !pip install scipy statsmodels --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.stattools import acf, pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are required to do this in order to avoid \"FutureWarning\" issues.\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bus Ridership Data\n",
    "> We're going to work with bus ridership data from the 1970s and 1980s. We have:\n",
    "- `date`: the start date for that month's ridership.\n",
    "- `bus_ridership`: how many people rode the bus each month (in thousands).\n",
    "\n",
    "### Portland Precipitation Data\n",
    "> We also have [precipitation data](https://w2.weather.gov/climate/local_data.php?wfo=PQR) measuring the amount of precipitation that fell at Portland's airport during the same dates as the bus ridership data was collected (1973-1982).\n",
    "- `YR`: the year the data was measured.\n",
    "- `MO`: the month the data was measured.\n",
    "- `total_precip`: the amount of precipitation (in inches)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data.\n",
    "bus = pd.read_csv('./datasets/bus.csv')\n",
    "\n",
    "# Check out first five rows.\n",
    "bus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data.\n",
    "precip = pd.read_csv('./datasets/precipitation.csv')\n",
    "\n",
    "# Check out first five rows.\n",
    "precip.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the data together.\n",
    "portland = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portland.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Date Index for the Data\n",
    "We are going to change our index to match the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the \"date\" column to set the index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that we did this correctly.\n",
    "portland.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the index only.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than have the index show the start date for the month, let it be the end date so it reflects when the value was recorded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit the index.\n",
    "portland.index = pd.date_range('1/1/1973', # start date is January 1, 1973\n",
    "                               periods=len(portland.index), # we want one period per entry\n",
    "                               freq='M') # frequency in months\n",
    "\n",
    "# Confirm we edited the index properly.\n",
    "portland.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this raw data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure size.\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Generate line plot of bus_ridership.\n",
    "\n",
    "plt.title(label='Monthly Ridership (in thousands)', fontsize=18);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Check: How would you describe this data?</summary>\n",
    "    \n",
    "- The data are correlated with one another.\n",
    "- The mean (straight-line trend) is increasing.\n",
    "- There appears to be some seasonality each year; this is especially apparent in the 1976-1979 window.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "\n",
    "Our goal, as with all train/test splits, is to:\n",
    "- avoid overfitting in our model, and\n",
    "- to get an unbiased estimate of model performance on new, \"unseen\" data.\n",
    "\n",
    "When fitting a time series model, we shouldn't do a random train-test split like we do with non-correlated data.\n",
    "\n",
    "Since our goal with time series analysis is almost always to forecast values forward in time, the idea with a time series train/test split is to train on earlier data and test/evaluate on later data.\n",
    "\n",
    "Most commonly, we'll set our:\n",
    "- training set to be the \"first\" 67% - 80% of our data timewise.\n",
    "- test set be the \"last\" 20% - 33% timewise.\n",
    "\n",
    "Let's split our dataframe by taking the first 80% of rows for training and the rest for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What index gives us our 80th percentile of rows?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set training data to be first 80% of rows.\n",
    "train =\n",
    "\n",
    "# Check shape to confirm we did this properly.\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set testing data to be last 20% of rows.\n",
    "test =\n",
    "\n",
    "# Check shape to confirm we did this properly.\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA Model\n",
    "\n",
    "An [ARIMA model](http://www.statsmodels.org/stable/generated/statsmodels.tsa.arima_model.ARIMA.html#statsmodels.tsa.arima_model.ARIMA) is a very useful model that forms the basis for most of time series modeling.\n",
    "\n",
    "ARIMA stands for:\n",
    "- Integrated\n",
    "- AutoRegressive\n",
    "- Moving Average models.\n",
    "\n",
    "*(That ordering isn't a typo)*.\n",
    "\n",
    "There are three pieces to ARIMA modeling.\n",
    "1. \"Differencing\" step.\n",
    "2. Autoregressive piece.\n",
    "3. Moving average piece.\n",
    "\n",
    "We'll cover each of these in order.\n",
    "\n",
    "### Differencing\n",
    "\n",
    "The purpose of the differencing step is to satisfy one assumption that is crucial to fitting an ARIMA model: **stationarity**.\n",
    "\n",
    "#### Stationarity\n",
    "\n",
    "Stationarity, formally, means that our time series:\n",
    "- has a constant mean over time.\n",
    "- has an autocorrelation that only depends on lag $k$, not on time $t$. (That is, $Corr(Y_t, Y_{t-k})$ should only depend on how far apart the observations are in time.)\n",
    "\n",
    "Informally, stationarity means that there aren't systematic changes in our time series over time.\n",
    "- A sine curve is a good example of a stationary time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "t = np.linspace(0, 15, 100)\n",
    "y = 5 * np.sin(t) + np.random.normal(0, 2, 100)\n",
    "\n",
    "plt.scatter(t, y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem is, many time series **aren't stationary**.\n",
    "- The amount that stock prices vary on a day-to-day basis aren't going to be the same.\n",
    "- Crop prices may increase or decrease over time; assuming a constant mean here doesn't make sense.\n",
    "\n",
    "So, what do we do?\n",
    "- We'll check to see if our data are stationary.\n",
    "- If our data aren't stationary, then that's where we difference our time series.\n",
    "\n",
    "#### Checking for Stationarity: the Augmented Dickey-Fuller Test\n",
    "\n",
    "The [augmented Dickey-Fuller test](https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test) is a hypothesis test that tests for stationarity. We assume that our data are not stationary. With enough evidence, we may accept that our data are stationary.\n",
    "\n",
    "Specifically, the test is as follows:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "&H_0:& \\text{not stationary} \\\\\n",
    "&H_A:& \\text{stationary}\n",
    "\\end{eqnarray}\n",
    "$$\n",
    "\n",
    "<details><summary>Thus, would a small $p$-value or a large $p$-value give us evidence that our time series is stationary?</summary>\n",
    "\n",
    "- A small $p$-value would give us evidence to reject the null hypothesis, meaning we accept that our time series is stationary.\n",
    "</details>\n",
    "\n",
    "\n",
    "### Integrated Autoregressive Moving Average (ARIMA) Models\n",
    "\n",
    "Often, our time series data will see both long-term trends **and** sudden fluctuations. Thus, we want to combine AR and MA models together.\n",
    "\n",
    "<details><summary>Check: What are some examples where we might see both long-term trends and sudden fluctuations in our time series data? </summary>\n",
    "\n",
    "- Stock price data. Stocks increase and decrease over time, but news or other stock changes may have sudden effects on prices.\n",
    "- Gas or oil prices. Similar logic as stock prices.\n",
    "- Public transportation ridership. While public transportation may see slow changes over time, marketing campaigns, changes in price, or accidents may have a sudden, unforeseen shock on ridership.\n",
    "</details>\n",
    "\n",
    "An [ARIMA model](http://www.statsmodels.org/stable/generated/statsmodels.tsa.arima_model.ARIMA.html#statsmodels.tsa.arima_model.ARIMA) is a very useful and very general model. We are literally just adding together our AR(p) and MA(q) models, with one additional change.\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "Y_t - Y_{t-d} &=& AR(p) + MA(q) \\\\\n",
    "&=& \\mu + \\sum_{k=1}^p \\beta_kY_{t-k} + \\sum_{i=1}^q w_i\\varepsilon_{t-i} + \\varepsilon_t\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Note that we are not predicting $Y_t$, but instead $Y_t - Y_{t-d}$. We difference our time series. This is because, in order for AR, MA, and ARIMA models to work, we need to meet one assumption: **stationarity**.\n",
    "\n",
    "\n",
    "\n",
    "### Augmented Dickey-Fuller Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code written by Joseph Nelson.\n",
    "\n",
    "def interpret_dftest(dftest):\n",
    "    dfoutput = pd.Series(dftest[0:2], index=['Test Statistic','p-value'])\n",
    "    return dfoutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>How would we interpret this $p$-value? </summary>\n",
    "    \n",
    "- Remember that we compare our $p$-value to $\\alpha$, which is usually set at 0.10, 0.05, or 0.01. Because $p = 0.87$, it is larger than any $\\alpha$ we'd reasonably pick. Thus, we cannot accept that our series `bus_ridership` is stationary.\n",
    "</details>\n",
    "\n",
    "##### In order to achieve stationarity, we need to difference!\n",
    "\n",
    "Differencing our time series means that instead of modeling our time series $Y_t$ directly, we'll model some difference:\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "\\Delta_t &=& Y_t - Y_{t-d}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Maybe the time series $Y_1, Y_2, \\ldots$ is not stationary... but the difference between time period $t-d$ and time period $t$ might be!\n",
    "\n",
    "Why do we difference? \n",
    "- Differencing allows us to get a stationary time series out of a non-stationary time series.\n",
    "- This means that we'll be able to fit an ARIMA model to the **differenced** data!\n",
    "\n",
    "We'll start with a difference of $d = 1$ and iterate upward until we find a value of $d$ that makes our time series stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a for loop to find the lowest difference value d.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this process, we would conclude that we should difference our time series by a lag of $d=4$.\n",
    "- Rather than modeling $Y_t$ directly, we'll model $\\Delta_t = Y_t - Y_{t-4}$.\n",
    "- If we generate autocorrelation and partial autocorrelation plots moving forward, then we should generate plots of the **differenced** time series, not the original time series!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three pieces to ARIMA modeling.\n",
    "1. \"Differencing\" step.\n",
    "2. Autoregressive piece.\n",
    "3. Moving average piece.\n",
    "\n",
    "### Autoregressive Piece\n",
    "\n",
    "The next piece to ARIMA modeling that we'll cover is the **autoregressive** piece, commonly abbreviated `AR`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Check: Without us covering it, what do you think the autoregressive piece might do?</summary>\n",
    "\n",
    "- An autoregressive model is where we regress a variable on itself by regressing newer values on older values. For example, $Y_t = \\beta_0 + \\beta_1Y_{t-1} + \\beta_2Y_{t-2}$.\n",
    "- A helpful hint to remembering autoregressive models is to think about the prefix \"auto:\"\n",
    "    - Autocorrelation is the correlation of one variable with itself. \n",
    "    - An autobiography is a book written by a person, about that same person. \n",
    "    - An autotransplant is a surgical procedure in which an organ is transplanted from a person to that same person.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autoregressive piece to the ARIMA model is responsible for **modeling the long-term trends** in our time series, like:\n",
    "- the changes in crop yield over time in response to climate change, or \n",
    "- the relatively steady increase of employees within an organization over time. \n",
    "\n",
    "The autoregressive piece **doesn't handle sudden, random shocks well**, like:\n",
    "- a wildfire or overly rainy season dramatically impacting crop yield, or\n",
    "- a massive acquisition/layoff that leads to a sudden jump/drop in the number of employees in an organization.\n",
    "\n",
    "The autoregressive piece of our ARIMA model will learn regression coefficients on the features that are the previous $p$ values. \n",
    "- An $AR(1)$ piece includes one prior value: $\\beta_0 + \\beta_1Y_{t-1}$\n",
    "- An $AR(2)$ piece includes two prior values: $\\beta_0 + \\beta_1Y_{t-1} + \\beta_2Y_{t-2}$\n",
    "- An $AR(p)$ piece includes $p$ prior values: $\\beta_0 + \\sum_{k=1}^p \\beta_kY_{t-k}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Check: How do you think we might decide on a value of $p$?</summary>\n",
    "\n",
    "- We could use our autocorrelation plot to see for what values of $k$ there is a significant correlation between $Y_t$ and $Y_{t-k}$.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure/axes.\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "\n",
    "# Generate plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visual:\n",
    "| Index | $Y_t$ | $Y_{t-1}$ | $Y_{t-2}$ | $Y_{t-3}$ |\n",
    "|-------|-------|-----------|-----------|-----------|\n",
    "| 1     | $y_1$ | NaN       | NaN       | NaN       |\n",
    "| 2     | $y_2$ | $y_1$     | NaN       | NaN       |\n",
    "| 3     | $y_3$ | $y_2$     | $y_1$     | NaN       |\n",
    "| 4     | $y_4$ | $y_3$     | $y_2$     | $y_1$     |\n",
    "\n",
    "- The left-most value of the autocorrelation plot is $Corr(Y_t, Y_t)$. This should always be 1! (The height of the blue dot will always be 1.)\n",
    "- The next value (moving one step to the right) of the autocorrelation plot visualizes $Corr(Y_t, Y_{t-1})$. The height of the blue dot here is about 0.95.\n",
    "- The next value of the autocorrelation plot visualizes $Corr(Y_t, Y_{t-2})$.\n",
    "- And so on..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Based on the plot above, for what lags $k$ is $Y_t$ significantly correlated with $Y_{t-k}$?</summary>\n",
    "    \n",
    "#### This is the main point of interpreting an autocorrelation plot.\n",
    "- Remember that the autocorrelation plot above shows that observations are highly correlated with one another. \n",
    "- For example, this plot shows that observations that are one time lag apart have a correlation around 60%. Observations that are two time lags apart have a correlation around 30%. (And so on...)\n",
    "- The blue band indicates the 95% confidence interval for these correlations.\n",
    "    - Observations inside the blue band mean that there is no significant correlations between $Y_t$ and $Y_{t-k}$ for lag $k$.\n",
    "    - Observations outside the blue band mean that there **is** a significant correlation between $Y_t$ and $Y_{t-k}$ for lag $k$.\n",
    "\n",
    "#### Thus, there is a statistically significant correlation between $Y_t$ and $Y_{t-k}$ for $k = 1, 2, 4, 5, 6, 7, 8, 12, and 24$.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Check: What might be a downside of relying solely on this plot?</summary>\n",
    "\n",
    "- If $Y_t$ is correlated with $Y_{t-1}$ and $Y_{t-2}$, then $Y_{t-1}$ and $Y_{t-2}$ are also likely correlated. We should have some way to account for how correlated all these are. **Enter the partial autocorrelation plot!**\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set figure/axes.\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "\n",
    "# Generate plot.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>How would you interpret the partial autocorrelation plot here?</summary>\n",
    "\n",
    "### Interpret the partial autocorrelation plot.\n",
    "1. The partial autocorrelation plot above shows that observations are highly correlated with one another. \n",
    "2. **However, the partial autocorrelation plot checks for the correlation between observations, conditioning on all lower-lag autocorrelations.** (That is, the partial autocorrelation between $Y_t$ and $Y_{t-2}$ is the correlation between $Y_t$ and $Y_{t-2}$ that has already taken into account the autocorrelation between $Y_t$ and $Y_{t-1}$.)\n",
    "3. The blue band indicates the 95% confidence interval for these correlations.\n",
    "    - Observations inside the blue band mean that there is no significant correlations between $Y_t$ and $Y_{t-k}$ for lag $k$, **accounting for all lower-order lags**.\n",
    "    - Observations outside the blue band mean that there **is** a significant correlation between $Y_t$ and $Y_{t-k}$ for lag $k$, **accounting for all lower-order lags**.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining a Value of $p$ based on the ACF and PACF.\n",
    "\n",
    "If the PACF (partial autocorrelation function) has a sharp cut-off and the lag-1 ACF (autocorrelation function) value is positive, choose $p$ to be the lag in the PACF before the cut-off.\n",
    "- Note: $p=1$ is the most common.\n",
    "\n",
    "If the PACF does not have a sharp cut-off or the lag-1 ACF value is not positive, then let $p=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Based on the ACF and PACF, what value of $p$ would you select?</summary>\n",
    "\n",
    "- The PACF has a sharp cut-off between lag 1 and lag 2.\n",
    "- The first lag in the ACF is positive.\n",
    "- Thus, we should set $p=1$.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit an ARIMA model.\n",
    "\n",
    "There are three pieces to ARIMA modeling.\n",
    "1. \"Differencing\" step.\n",
    "2. Autoregressive piece.\n",
    "3. Moving average piece.\n",
    "\n",
    "We haven't yet learned about the moving average piece, but let's fit an ARIMA model now, then come back to talk about the moving average piece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ARIMA model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model.\n",
    "\n",
    "# Remember that, in statsmodels, we pass our data \n",
    "# in when we instantiate the model!\n",
    "\n",
    "model = \n",
    "\n",
    "# Note that we manually difference our data.\n",
    "# In the present version of statsmodels, only\n",
    "# certain values of d are supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>What do these predicted values represent?</summary>\n",
    "\n",
    "- These predicted values represent $\\hat{\\Delta}_t$, which is the 4-lagged\n",
    "- The first observation represents how much the bus ridership will change between January 1973 and May 1973.\n",
    "- The second observation represents how much the bus ridership will change between February 1973 and June 1973.\n",
    "- And so on.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data.\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(train['bus_ridership'].diff(4).dropna(), color = 'blue')\n",
    "plt.plot(preds, color = 'orange')\n",
    "plt.title(label = 'Bus Ridership with ARIMA(1,4,0) Predictions', fontsize=18)\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate these predictions using R^2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would call the above model an $ARIMA(1, 4, 0)$ model.\n",
    "\n",
    "In general, ARIMA is parameterized as $ARIMA(p, d, q)$, where: \n",
    "- $d$ is the order of differencing we found using the Augmented Dickey-Fuller test.\n",
    "- $p$ is the number of autoregressive terms in our model.\n",
    "- and $q$ is coming up next!\n",
    "\n",
    "There are three pieces to ARIMA modeling.\n",
    "1. \"Differencing\" step.\n",
    "2. Autoregressive piece.\n",
    "3. Moving average piece.\n",
    "\n",
    "### Moving Average Piece\n",
    "\n",
    "The final piece to ARIMA modeling that we'll cover is the **moving average** piece, commonly abbreviated `MA`.\n",
    "\n",
    "In the moving average piece, we take **previous error terms** as inputs. They predict the next value based on deviations from previous predictions.\n",
    "- A $MA(1)$ piece regresses $Y_t$ on one prior error: $\\mu + w_1\\varepsilon_{t-1} + \\varepsilon_t$\n",
    "- A $MA(2)$ piece regresses $Y_t$ on two prior errors: $\\mu + w_1\\varepsilon_{t-1} + w_2\\varepsilon_{t-2} + \\varepsilon_t$\n",
    "- A $MA(3)$ piece regresses $Y_t$ on three prior errors: $\\mu + w_1\\varepsilon_{t-1} + w_2\\varepsilon_{t-2} + w_3\\varepsilon_{t-3} + \\varepsilon_t$\n",
    "\n",
    "We denote this piece as $MA(q)$, where $q$ indicates the number of previous errors to incorporate.\n",
    "\n",
    "The moving average piece **does handle sudden, random shocks well**, (unlike the AR piece) like:\n",
    "- a wildfire or overly rainy season dramatically impacting crop yield, or\n",
    "- a massive acquisition/layoff that leads to a sudden jump/drop in the number of employees in an organization.\n",
    "\n",
    "<details><summary>Technical Bonus Note:</summary>\n",
    "\n",
    "- Because the error terms ($\\varepsilon$) are unobserved, we rely on sophisticated algorithms to estimate the coefficients $w_i$ when fitting this model. [Check out a paper on the topic here.](https://www.it.uu.se/research/publications/reports/2006-022/2006-022-nc.pdf)\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determining a Value of $q$ based on the ACF and PACF.\n",
    "\n",
    "If the PACF (partial autocorrelation function) has a sharp cut-off and the lag-1 ACF (autocorrelation function) value is negative, choose $q$ to be the lag in the ACF before the cut-off.\n",
    "- Note: $p$ is determined by the lag in the PACF; $q$ is determined by the lag in the ACF.\n",
    "\n",
    "If the PACF does not have a sharp cut-off or the lag-1 ACF value is not negative, then let $q=0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Based on the ACF and PACF, what value of $q$ would you select?</summary>\n",
    "\n",
    "- The PACF has a sharp cut-off between lag 1 and lag 2.\n",
    "- The first lag in the ACF is positive.\n",
    "- Thus, we should set $q=0$.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recap:** The AR piece is appropriate when modeling long-term trends in our process. The MA piece is appropriate when modeling sudden fluctuations in our process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pulling the ARIMA Model Together\n",
    "\n",
    "There are three pieces to ARIMA modeling.\n",
    "1. \"Differencing\" step.\n",
    "2. Autoregressive piece.\n",
    "3. Moving average piece.\n",
    "\n",
    "Often, our time series data will see both long-term trends **and** sudden fluctuations. Thus, we want to combine AR and MA pieces together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary>Check: What are some examples where we might see both long-term trends and sudden fluctuations in our time series data? </summary>\n",
    "\n",
    "- Stock price data. Stocks increase and decrease over time, but news or other stock changes may have sudden effects on prices.\n",
    "- Gas or oil prices. Similar logic as stock prices.\n",
    "- Public transportation ridership. While public transportation may see slow changes over time, marketing campaigns, changes in price, or accidents may have a sudden, unforeseen shock on ridership.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- An ARIMA(p, d, q) model is specified by:\n",
    "    - how many lags $p$ we regress $Y_t$ on.\n",
    "    - how many errors $q$ we regress $Y_t$ on.\n",
    "    - and how many differences $d$ we want to calculate in order to achieve stationarity.\n",
    "\n",
    "An $ARIMA(p,d,q)$ model is specified as follows:\n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "ARIMA(p,d,q) \\Rightarrow Y_t - Y_{t-d} &=& AR(p) + MA(q) \\\\\n",
    "Y_t - Y_{t-d} &=& \\mu + \\sum_{k=1}^p \\beta_kY_{t-k} + \\sum_{i=1}^q w_i\\varepsilon_{t-i} + \\varepsilon_t\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "Depending on our values of $p$, $d$, and $q$, we might refer to these models by slightly different names.\n",
    "\n",
    "- If $d=0$ and $q=0$, an AR(p) model is specified by how many lags $p$ we regress $Y_t$ on.\n",
    "- If $d=0$ and $p=0$, an MA(q) model is specified by how many errors $q$ we regress $Y_t$ on.\n",
    "- If $d=0$, an ARMA(p, q) model is specified by how many lags $p$ and how many errors $q$ we regress $Y_t$ on.\n",
    "\n",
    "| p | d | q |          Model         |\n",
    "|:-:|:-:|:-:|:----------------------:|\n",
    "| 1 | 0 | 0 |  ARIMA(1,0,0) = AR(1)  |\n",
    "| 0 | 0 | 1 |  ARIMA(0,0,1) = MA(1)  |\n",
    "| 1 | 0 | 1 | ARIMA(1,0,1) = ARMA(1) |\n",
    "| 1 | 1 | 1 |      ARIMA(1,1,1)      |\n",
    "| 1 | 1 | 0 |      ARIMA(1,1,0)      |\n",
    "| 0 | 1 | 1 |      ARIMA(0,1,1)      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we find the right values of $p$, $d$, $q$?\n",
    "- Manually looking through plots and the Augmented Dickey-Fuller test is the best way to go (like we did above).\n",
    "- \"GridSearch\" to find the right difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(4):\n",
    "    for d in range(4):\n",
    "        for q in range(4):\n",
    "            arima = ARIMA(endog = train['bus_ridership'].astype('float32'), # Y variable\n",
    "                          order = (p, d, q)) # (p, d, q)\n",
    "            model = arima.fit()\n",
    "            preds = model.predict()\n",
    "            print(f'The R^2 score for (p = {p}, d = {d}, q = {q}) is {r2_score(train[\"bus_ridership\"], preds)}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, finding coefficients for an MA (or ARMA or ARIMA) model is difficult.\n",
    "\n",
    "For example, consider an $MA(2)$ model.\n",
    "$$MA(2) \\Rightarrow Y_t = \\mu + w_1\\varepsilon_{t-1} + w_2\\varepsilon_{t-2} + \\varepsilon_t$$\n",
    "\n",
    "The model requires us to regress on errors, but we don't actually observe these errors. (The algorithm for fitting this is complicated and is beyond the scope of this lesson. [Check more out here](https://www.it.uu.se/research/publications/reports/2006-022/2006-022-nc.pdf).)\n",
    "\n",
    "There are a few ways to handle this:\n",
    "- Add a seasonal component to our model.\n",
    "- Specify a different model.\n",
    "- \"Hack\" our answer by adding `try` and `except` statements to our for loops.\n",
    "\n",
    "<details><summary>What is the purpose of try and except statements?</summary>\n",
    "\n",
    "- If our code encounters an error, then it will automatically stop. Sometimes this is good (so we can debug) but sometimes this isn't desirable!\n",
    "- `try` and `except` statements allow us to \"try\" to do something and, if there's an error, we can just `pass` it so that our code doesn't stop running.\n",
    "- This isn't always a good thing... errors are usually telling us that something is wrong. But we're going to hack our answer here so that we can check all values of $p$, $d$, and $q$ and just not run the model if some values of $p$, $d$, and $q$ are invalid.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(4):\n",
    "    for d in range(4):\n",
    "        for q in range(4):\n",
    "            try:\n",
    "                arima = ARIMA(endog = train['bus_ridership'].astype('float32'), # Y variable\n",
    "                              order = (p, d, q)) # (p, d, q)\n",
    "                model = arima.fit()\n",
    "                preds = model.predict()\n",
    "                print(f'The R^2 score for (p = {p}, d = {d}, q = {q}) is {r2_score(train[\"bus_ridership\"], preds)}.')\n",
    "            \n",
    "            except:\n",
    "                pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
